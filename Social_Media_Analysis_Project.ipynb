{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imgix import UrlBuilder\n",
    "from google.cloud import vision\n",
    "from google.oauth2 import service_account\n",
    "import os\n",
    "import lzma\n",
    "import json\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from gensim.matutils import Sparse2Corpus\n",
    "from gensim.models import CoherenceModel\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Google Cloud credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your service account key file\n",
    "key_path = \"/Users/qianlou/Documents/GitHub/Social-Media-Analysis/forward-cacao-420716-6d4b68655e6d.json\"\n",
    "\n",
    "# Set up Google Vision client\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "# Initialize the Vision API Client\n",
    "client = vision.ImageAnnotatorClient(credentials=credentials)\n",
    "\n",
    "def detect_labels(image_path):\n",
    "    \"\"\"Detect labels in the image at the given path using Google Vision API.\"\"\"\n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "    image = vision.Image(content=content)\n",
    "    response = client.label_detection(image=image)\n",
    "    return [label.description for label in response.label_annotations]\n",
    "\n",
    "def find_key(data, target_key):\n",
    "    \"\"\"Recursively search for a key in JSON data.\"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            if key == target_key:\n",
    "                return value\n",
    "            result = find_key(value, target_key)\n",
    "            if result:\n",
    "                return result\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            result = find_key(item, target_key)\n",
    "            if result:\n",
    "                return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data\n",
    "\n",
    "URL Link: https://www.kaggle.com/datasets/thecoderenroute/instagram-posts-dataset?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_path = '/Users/qianlou/Documents/GitHub/Social-Media-Analysis/Data'\n",
    "\n",
    "data = []  # List to hold all data extracted and processed\n",
    "\n",
    "# Walk through the directory structure\n",
    "for root, dirs, files in os.walk(data_folder_path):\n",
    "    folder_name = os.path.basename(root)\n",
    "    parts = folder_name.rsplit('_', 4)  # Split from the right to capture the last four elements distinctly\n",
    "    \n",
    "    if len(parts) < 5:\n",
    "        continue  # Skip folders that do not have the expected number of parts\n",
    "\n",
    "    profile_name = parts[0]  # Everything before the last four parts is the profile name\n",
    "    follower_count, post_id, likes, comments = parts[1:]  # Unpack the last four parts in order\n",
    "    \n",
    "    all_labels = []\n",
    "    json_data = {}\n",
    "\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        if file.endswith('.json.xz'):\n",
    "            with lzma.open(file_path, 'rt') as json_file:\n",
    "                json_data = json.load(json_file)\n",
    "        elif file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image_labels = detect_labels(file_path)\n",
    "            all_labels.extend(image_labels)\n",
    "\n",
    "    engagement_score = find_key(json_data, 'edge_media_to_comment')\n",
    "    engagement_count = engagement_score.get('count') if engagement_score and isinstance(engagement_score, dict) and 'count' in engagement_score else None\n",
    "\n",
    "    if all_labels:\n",
    "        data.append({\n",
    "            'profile_name': profile_name,\n",
    "            'follower_count': follower_count,\n",
    "            'post_id': post_id,\n",
    "            'likes': likes,\n",
    "            'comments': comments,\n",
    "            'labels': ' '.join(all_labels),\n",
    "            'engagement_score': engagement_count\n",
    "        })\n",
    "\n",
    "# Convert the list of data into a DataFrame\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1968 entries, 1489 to 201\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   profile_name      1968 non-null   object\n",
      " 1   follower_count    1968 non-null   object\n",
      " 2   post_id           1968 non-null   object\n",
      " 3   likes             1968 non-null   object\n",
      " 4   comments          1968 non-null   object\n",
      " 5   labels            1968 non-null   object\n",
      " 6   engagement_score  1968 non-null   int64 \n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 123.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert image labels to a matrix of token counts\n",
    "vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "X = vectorizer.fit_transform(data_df['labels'])\n",
    "\n",
    "# Fit LDA model\n",
    "lda = LatentDirichletAllocation(n_components=10, random_state=0)  # Adjust n_components as needed\n",
    "topics = lda.fit_transform(X)\n",
    "\n",
    "# Display top 25 words for each topic\n",
    "features = vectorizer.get_feature_names_out()\n",
    "top_words = lambda t: [features[i] for i in np.argsort(t)[:-26:-1]]\n",
    "topic_words = ([top_words(t) for t in lda.components_])\n",
    "print([' '.join(t) for t in topic_words])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engagement Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add topic distributions as features to the DataFrame\n",
    "topic_columns = [f'topic_{i}' for i in range(lda.components_.shape[0])]\n",
    "for index, topic_dist in enumerate(topics):\n",
    "    data_df.loc[index, topic_columns] = topic_dist\n",
    "\n",
    "# Sort data based on engagement and find quartiles\n",
    "data_df.sort_values('comments', ascending=False, inplace=True)\n",
    "quartile_size = len(data_df) // 4\n",
    "top_quartile = data_df.head(quartile_size)\n",
    "bottom_quartile = data_df.tail(quartile_size)\n",
    "\n",
    "# Compare average topic weights between the top and bottom quartiles\n",
    "average_top = top_quartile[topic_columns].mean()\n",
    "average_bottom = bottom_quartile[topic_columns].mean()\n",
    "comparison_df = pd.DataFrame({'Top Quartile': average_top, 'Bottom Quartile': average_bottom})\n",
    "print(comparison_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
